# Deep Reinforcement Learning Baselines with CNTK

🔴 Incomplete. Checkout Progress Below 🔴

## Progress Tracker 
(4 week plan)
### Week 1/4
| Algorithm   | Implementation | Pre-Trained Policies |
| ----------- | -------------- | -------------------- |
| Simple DQN  | ✔️             | ❌                  |
| DQN         | ❌             | ❌                  |
| Double DQN  | ❌             | ❌                  |
| REINFORCE   | ❌             | ❌                  |
| A2C         | ❌             | ❌                  |
| A3C         | ❌             | ❌                  |
| PPO         | ❌             | ❌                  |
| DDPG        | ❌             | ❌                  |
| SAC         | ❌             | ❌                  |
| TRPO        | ❌             | ❌                  |
| HER         | ❌             | ❌                  |
| GAIL        | ❌             | ❌                  |

This repository is meant to teach the intricacies of writing advanced Deep Reinforcement Algorithms in CTNK. A lot of good repositories for RL exists but use Tensorflow/PyTorch. Most of them are easy to USE libraries rather than easy to UNDERSTAND libraries. There is a steep learning curve for someone new to the field who wants to modify existing architectures or explore possibilities.

The code in this repository is heavily commented and the comments serve as a guide to read through the entire library and learn reinforcement learning as well as CNTK API. On flip side, this may not be a production grade library although it achieves state of the art results on Atari environments.

The code is used as a guide, in weekly Deep Learning meetings at Ohio State University, for teaching -

1. How to read an RL paper
2. How to implement it in CNTK (or library of your choice)

I choose CNTK because -
1. I joined Microsoft recently
2. Lack of tutorials/comprehensive documentation in CNTK

Reinforcement learning architectures contain more complexities then standard DNNs. Each paper has its own implementation quirks and therefore understanding code of existing algorithms clearly lets you write/discover novel architectures.
